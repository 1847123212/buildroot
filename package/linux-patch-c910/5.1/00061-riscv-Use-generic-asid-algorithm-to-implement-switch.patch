From f47ce3caf157760c28e5056f1d73aaea22f95cb5 Mon Sep 17 00:00:00 2001
From: Guo Ren <ren_guo@c-sky.com>
Date: Wed, 9 Oct 2019 15:20:26 +0800
Subject: [PATCH 2/2] riscv: Use generic asid algorithm to implement switch_mm

Use linux generic asid/vmid algorithm to implement csky
switch_mm function. The algorithm is from arm and it could
work with SMP system. It'll help reduce tlb flush for
switch_mm in task/vm switch.

Signed-off-by: Guo Ren <ren_guo@c-sky.com>
---
 arch/riscv/include/asm/csr.h         |  6 +++++
 arch/riscv/include/asm/mmu.h         |  1 +
 arch/riscv/include/asm/mmu_context.h | 22 ++++++++++-------
 arch/riscv/mm/Makefile               |  1 +
 arch/riscv/mm/context.c              | 46 ++++++++++++++++++++++++++++++++++++
 5 files changed, 67 insertions(+), 9 deletions(-)
 create mode 100644 arch/riscv/mm/context.c

diff --git a/arch/riscv/include/asm/csr.h b/arch/riscv/include/asm/csr.h
index 28a0d1c..b02ee93 100644
--- a/arch/riscv/include/asm/csr.h
+++ b/arch/riscv/include/asm/csr.h
@@ -45,10 +45,16 @@
 #define SATP_PPN     _AC(0x003FFFFF, UL)
 #define SATP_MODE_32 _AC(0x80000000, UL)
 #define SATP_MODE    SATP_MODE_32
+#define SATP_ASID_BITS         9
+#define SATP_ASID_SHIFT        22
+#define SATP_ASID_MASK         _AC(0x1FF, UL)
 #else
 #define SATP_PPN     _AC(0x00000FFFFFFFFFFF, UL)
 #define SATP_MODE_39 _AC(0x8000000000000000, UL)
 #define SATP_MODE    SATP_MODE_39
+#define SATP_ASID_BITS         16
+#define SATP_ASID_SHIFT        44
+#define SATP_ASID_MASK         _AC(0xFFFF, UL)
 #endif
 
 /* Interrupt Enable and Interrupt Pending flags */
diff --git a/arch/riscv/include/asm/mmu.h b/arch/riscv/include/asm/mmu.h
index 5df2dcc..1f25b81 100644
--- a/arch/riscv/include/asm/mmu.h
+++ b/arch/riscv/include/asm/mmu.h
@@ -18,6 +18,7 @@
 #ifndef __ASSEMBLY__
 
 typedef struct {
+	atomic64_t asid;
 	void *vdso;
 #ifdef CONFIG_SMP
 	/* A local icache flush is needed before user execution can resume. */
diff --git a/arch/riscv/include/asm/mmu_context.h b/arch/riscv/include/asm/mmu_context.h
index 336d60e..c79b088 100644
--- a/arch/riscv/include/asm/mmu_context.h
+++ b/arch/riscv/include/asm/mmu_context.h
@@ -23,18 +23,16 @@
 #include <asm/tlbflush.h>
 #include <asm/cacheflush.h>
 
+#define ASID_MASK		((1 << CONFIG_CPU_ASID_BITS) - 1)
+#define cpu_asid(mm)		(atomic64_read(&mm->context.asid) & ASID_MASK)
+
+#define init_new_context(tsk,mm)	({ atomic64_set(&(mm)->context.asid, 0); 0; })
+
 static inline void enter_lazy_tlb(struct mm_struct *mm,
 	struct task_struct *task)
 {
 }
 
-/* Initialize context-related info for a new mm_struct */
-static inline int init_new_context(struct task_struct *task,
-	struct mm_struct *mm)
-{
-	return 0;
-}
-
 static inline void destroy_context(struct mm_struct *mm)
 {
 }
@@ -69,6 +67,8 @@ static inline void flush_icache_deferred(struct mm_struct *mm)
 #endif
 }
 
+void check_and_switch_context(struct mm_struct *mm, unsigned int cpu);
+
 static inline void switch_mm(struct mm_struct *prev,
 	struct mm_struct *next, struct task_struct *task)
 {
@@ -79,6 +79,11 @@ static inline void switch_mm(struct mm_struct *prev,
 		 * routines in order to determine who should
 		 */
 		unsigned int cpu = smp_processor_id();
+		unsigned long asid =
+			(next->context.asid.counter & SATP_ASID_MASK)
+			<< SATP_ASID_SHIFT;
+
+		check_and_switch_context(next, cpu);
 
 		cpumask_clear_cpu(cpu, mm_cpumask(prev));
 		cpumask_set_cpu(cpu, mm_cpumask(next));
@@ -88,8 +93,7 @@ static inline void switch_mm(struct mm_struct *prev,
 		 * name to support binutils 2.29 which doesn't know about the
 		 * privileged ISA 1.10 yet.
 		 */
-		csr_write(sptbr, virt_to_pfn(next->pgd) | SATP_MODE);
-		local_flush_tlb_all();
+		csr_write(sptbr, virt_to_pfn(next->pgd) | SATP_MODE | asid);
 
 		flush_icache_deferred(next);
 	}
diff --git a/arch/riscv/mm/Makefile b/arch/riscv/mm/Makefile
index 5b58ada..1d1d9d3 100644
--- a/arch/riscv/mm/Makefile
+++ b/arch/riscv/mm/Makefile
@@ -11,3 +11,4 @@ obj-y += ioremap.o
 obj-y += cacheflush.o
 obj-y += dma-mapping.o
 obj-y += asid.o
+obj-y += context.o
diff --git a/arch/riscv/mm/context.c b/arch/riscv/mm/context.c
new file mode 100644
index 0000000..4111a8e
--- /dev/null
+++ b/arch/riscv/mm/context.c
@@ -0,0 +1,46 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (C) 2018 Hangzhou C-SKY Microsystems co.,ltd.
+
+#include <linux/bitops.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+
+#include <asm/asid.h>
+#include <asm/mmu_context.h>
+#include <asm/smp.h>
+#include <asm/tlbflush.h>
+
+static DEFINE_PER_CPU(atomic64_t, active_asids);
+static DEFINE_PER_CPU(u64, reserved_asids);
+
+struct asid_info asid_info;
+
+void check_and_switch_context(struct mm_struct *mm, unsigned int cpu)
+{
+	asid_check_context(&asid_info, &mm->context.asid, cpu, mm);
+}
+
+static void asid_flush_cpu_ctxt(void)
+{
+	local_flush_tlb_all();
+}
+
+static int asids_init(void)
+{
+	BUG_ON(((1 << SATP_ASID_BITS) - 1) <= num_possible_cpus());
+
+	if (asid_allocator_init(&asid_info, SATP_ASID_BITS, 1,
+				asid_flush_cpu_ctxt))
+		panic("Unable to initialize ASID allocator for %lu ASIDs\n",
+		      NUM_ASIDS(&asid_info));
+
+	asid_info.active = &active_asids;
+	asid_info.reserved = &reserved_asids;
+
+	pr_info("ASID allocator initialised with %lu entries\n",
+		NUM_CTXT_ASIDS(&asid_info));
+
+	return 0;
+}
+early_initcall(asids_init);
-- 
2.7.4

